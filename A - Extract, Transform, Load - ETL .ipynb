{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3295bcc",
   "metadata": {},
   "source": [
    "## Automatização de Relatórios Utilizando Dados GIS Vetoriais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf119b6a",
   "metadata": {},
   "source": [
    "### AUTOR: ADENILSON SILVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2100bf9",
   "metadata": {},
   "source": [
    "# EXTRAÇÃO, TRANSFORMAÇÃO E CARRAGAMENTO DE DADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2288e",
   "metadata": {},
   "source": [
    "####  1 - Importando bibliotecas e criando funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "510ca7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Importa o módulo 'os' para lidar com operações do sistema de arquivos\n",
    "import geopandas as gpd  # Biblioteca para trabalhar com dados geoespaciais, como shapefiles e GeoJSON\n",
    "import pandas as pd  # Usada para trabalhar com dados em formato de tabela (DataFrame)\n",
    "import fiona  # Utilizada para ler e escrever arquivos geoespaciais (formato shapefile, por exemplo)\n",
    "import chardet  # Usado para detectar a codificação de arquivos de texto\n",
    "import json  #  Biblioteca para trabalhar com dados no formato JSON\n",
    "from shapely.wkt import loads  # Importa a função 'loads' para converter strings WKT em objetos geométricos\n",
    "from google.cloud import bigquery  # Cliente para interagir com o Google BigQuery, serviço de data warehouse na nuvem\n",
    "from google.oauth2 import service_account  # Para autenticação com credenciais (chave JSON) em serviços do Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201d3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listar_shapefiles(diretorio_base):\n",
    "    \"\"\"\n",
    "    Lista todos os arquivos shapefile (.shp) encontrados em um diretório base e suas subpastas,\n",
    "    estruturando a hierarquia dos diretórios em colunas de um DataFrame pandas.\n",
    "\n",
    "    Parâmetros:\n",
    "    - diretorio_base (str): O caminho do diretório onde a busca por shapefiles deve começar.\n",
    "\n",
    "    Retorna:\n",
    "    - pandas.DataFrame: Um DataFrame contendo informações sobre cada shapefile encontrado. As colunas incluem:\n",
    "        - 'id': Um identificador único para cada shapefile (baseado no índice do DataFrame).\n",
    "        - 'caminho': O caminho completo do arquivo shapefile.\n",
    "        - 'nivel_1', 'nivel_2', ..., 'nivel_8': As partes da hierarquia do caminho do arquivo, divididas em até 8 níveis.\n",
    "                                               Se o caminho tiver menos de 8 níveis, as colunas restantes são preenchidas com None.\n",
    "        - 'shapefile_nome': O nome do arquivo shapefile.\n",
    "\n",
    "    Exemplo de uso:\n",
    "    Suponha que você tenha a seguinte estrutura de diretórios:\n",
    "    diretorio_base/\n",
    "        nivel_1/\n",
    "            nivel_2/\n",
    "                arquivo1.shp\n",
    "                arquivo2.shp\n",
    "        nivel_3/\n",
    "            arquivo3.shp\n",
    "\n",
    "    Ao chamar listar_shapefiles(\"diretorio_base\"), a função retornará um DataFrame com as seguintes informações:\n",
    "\n",
    "    | id | caminho                                       | nivel_1 | nivel_2 | nivel_3 | nivel_4 | nivel_5 | nivel_6 | nivel_7 | nivel_8 | shapefile_nome |\n",
    "    |----|-----------------------------------------------|---------|---------|---------|---------|---------|---------|---------|----------------|\n",
    "    | 0  | diretorio_base/nivel_1/nivel_2/arquivo1.shp   | nivel_1 | nivel_2 | None    | None    | None    | None    | None    | None    | arquivo1.shp   |\n",
    "    | 1  | diretorio_base/nivel_1/nivel_2/arquivo2.shp   | nivel_1 | nivel_2 | None    | None    | None    | None    | None    | None    | arquivo2.shp   |\n",
    "    | 2  | diretorio_base/nivel_3/arquivo3.shp           | nivel_3 | None    | None    | None    | None    | None    | None    | None    | arquivo3.shp   |\n",
    "\n",
    "    Observações:\n",
    "    - A função utiliza os.walk do módulo os para percorrer recursivamente o diretório base e suas subpastas.\n",
    "    - A hierarquia dos diretórios é limitada a 8 níveis. Se houver mais níveis, eles não serão incluídos nas colunas do DataFrame.\n",
    "    - A função depende das bibliotecas os e pandas estarem instaladas e importadas corretamente.\n",
    "    \"\"\"\n",
    "    registros = []\n",
    "    for root, _, arquivos in os.walk(diretorio_base):\n",
    "        for arquivo in arquivos:\n",
    "            if arquivo.endswith(\".shp\"):\n",
    "                caminho = os.path.join(root, arquivo)\n",
    "\n",
    "                # Criando a hierarquia dividindo o caminho\n",
    "                partes = caminho.replace(diretorio_base, \"\").strip(os.sep).split(os.sep)\n",
    "\n",
    "                # Garantindo um número fixo de colunas para hierarquia (ajustável)\n",
    "                niveis = partes[:-1]  # Tudo menos o arquivo shapefile\n",
    "                while len(niveis) < 8:\n",
    "                    niveis.append(None)\n",
    "\n",
    "                registros.append([caminho] + niveis + [arquivo])\n",
    "\n",
    "    colunas = [\"caminho\", \"nivel_1\", \"nivel_2\", \"nivel_3\", \"nivel_4\", \"nivel_5\", \"nivel_6\", \"nivel_7\", \"nivel_8\", \"shapefile_nome\"]\n",
    "    df_hierarquia = pd.DataFrame(registros, columns=colunas)\n",
    "\n",
    "    # Criando a coluna id baseada no índice\n",
    "    df_hierarquia.insert(0, \"id\", df_hierarquia.index)\n",
    "\n",
    "    return df_hierarquia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ebc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_geometrias(df_hierarquia):\n",
    "    \"\"\"\n",
    "    Carrega geometrias de arquivos shapefile (.shp) e seus atributos, convertendo-os para formato GeoJSON.\n",
    "\n",
    "    Parâmetros:\n",
    "    - df_hierarquia (pandas.DataFrame): Um DataFrame contendo informações sobre arquivos shapefile,\n",
    "      incluindo o caminho completo para cada arquivo. Este DataFrame deve ter pelo menos uma coluna\n",
    "      chamada 'caminho'.\n",
    "\n",
    "    Retorna:\n",
    "    - pandas.DataFrame: Um DataFrame com duas colunas:\n",
    "        - 'geometria_e_atributos': Dados GeoJSON representando as geometrias e atributos de cada shapefile.\n",
    "        - 'id_diretorio': O índice do DataFrame de entrada, usado para identificar a origem dos dados.\n",
    "\n",
    "    Descrição:\n",
    "    Esta função itera sobre as linhas de um DataFrame fornecido, onde cada linha contém o caminho\n",
    "    para um arquivo shapefile. A função tenta carregar cada shapefile, lida com possíveis problemas\n",
    "    de codificação, converte as geometrias e atributos para GeoJSON e armazena os resultados em um\n",
    "    novo DataFrame.\n",
    "\n",
    "    Tratamento de Erros:\n",
    "    - A função lida com erros de leitura de arquivos shapefile, tentando detectar a codificação correta\n",
    "      caso a leitura direta falhe.\n",
    "    - Se a conversão para GeoJSON falhar, a função imprime uma mensagem de erro e continua com o próximo arquivo.\n",
    "\n",
    "    Conversão para WGS 84:\n",
    "    - Garante que o sistema de referência de coordenadas (CRS) de cada GeoDataFrame seja WGS 84 (EPSG:4326).\n",
    "\n",
    "    Exemplo de uso:\n",
    "    Suponha que você tenha um DataFrame 'df_shapefiles' com uma coluna 'caminho' contendo os caminhos\n",
    "    para seus arquivos shapefile.\n",
    "\n",
    "    resultado = carregar_geometrias(df_shapefiles)\n",
    "    print(resultado.head())\n",
    "\n",
    "    Observações:\n",
    "    - A função depende das bibliotecas pandas, geopandas, json, chardet e fiona estarem instaladas.\n",
    "    - O GeoJSON resultante inclui tanto as geometrias quanto os atributos dos dados do shapefile.\n",
    "    - A coluna 'id_diretorio' no DataFrame de saída corresponde ao índice do DataFrame de entrada,\n",
    "      permitindo rastrear a origem dos dados.\n",
    "    \"\"\"\n",
    "    geometrias_atributos = pd.DataFrame(columns=['geometria_e_atributos', 'id_diretorio'])\n",
    "    for index, row in df_hierarquia.iterrows():\n",
    "        caminho = row[\"caminho\"]\n",
    "        try:\n",
    "            # Tentar carregar diretamente\n",
    "            gdf = gpd.read_file(caminho)\n",
    "        except Exception:\n",
    "            try:\n",
    "                # Detectar encoding e tentar novamente\n",
    "                with open(caminho, \"rb\") as f:\n",
    "                    resultado = chardet.detect(f.read(100))\n",
    "                encoding_detectado = resultado[\"encoding\"]\n",
    "                with fiona.open(caminho, encoding=encoding_detectado) as src:\n",
    "                    gdf = gpd.GeoDataFrame.from_features(src, crs=src.crs)\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar {caminho}: {e}\")\n",
    "                continue\n",
    "        # Garantir que CRS seja WGS 84\n",
    "        if gdf.crs and gdf.crs.to_epsg() != 4326:\n",
    "            gdf = gdf.to_crs(epsg=4326)\n",
    "        try:\n",
    "            gdf = gdf.apply(lambda col: col.astype(str) if col.dtype == 'datetime64[ms]' else col)\n",
    "            geojson_result = json.loads(gdf.to_json(indent=4, ensure_ascii=False))\n",
    "            geojson_result_str = json.dumps(geojson_result, ensure_ascii=False)\n",
    "            linha = pd.DataFrame({'geometria_e_atributos': [geojson_result_str], 'id_diretorio': [index]})\n",
    "            geometrias_atributos = pd.concat([geometrias_atributos, linha], ignore_index=True)\n",
    "            df_hierarquia_geometrias_e_atributos = df_hierarquia.merge(geometrias_atributos, left_on='id', right_on='id_diretorio').drop(columns=['id_diretorio'])\n",
    "            df_hierarquia_geometrias_e_atributos['id'] = df_hierarquia_geometrias_e_atributos['id'].astype('int64')\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao converter geometrias para JSON em {caminho}: {e}\")\n",
    "    return df_hierarquia_geometrias_e_atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771c2019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_dataset_bigquery(caminho_chave, project_id, nome_dataset, localizacao=\"US\"):\n",
    "    \"\"\"\n",
    "    Cria um dataset no Google BigQuery com base em um arquivo de credenciais\n",
    "    e retorna o cliente autenticado.\n",
    "\n",
    "    Parâmetros:\n",
    "    - caminho_chave: caminho para o arquivo JSON da conta de serviço.\n",
    "    - project_id: ID do projeto no GCP.\n",
    "    - nome_dataset: nome do dataset a ser criado.\n",
    "    - localizacao: localização do dataset (ex: 'US', 'southamerica-east1', etc).\n",
    "\n",
    "    Retorno:\n",
    "    - client: instância autenticada de bigquery.Client\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cria as credenciais e o cliente\n",
    "        credentials = service_account.Credentials.from_service_account_file(caminho_chave)\n",
    "        client = bigquery.Client(credentials=credentials, project=project_id)\n",
    "        # Define e cria o dataset\n",
    "        dataset_id = f\"{client.project}.{nome_dataset}\"\n",
    "        dataset = bigquery.Dataset(dataset_id)\n",
    "        dataset.location = localizacao\n",
    "        dataset = client.create_dataset(dataset, exists_ok=True)\n",
    "        print(f\"Dataset '{dataset.dataset_id}' criado com sucesso na região '{localizacao}'.\")\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao criar o dataset: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dcf81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enviar_para_bigquery(dados, caminho_chave, projeto_id, dataset_id, tabela_id):\n",
    "    '''\n",
    "    Envia os dados de um DataFrame para uma tabela no Google BigQuery, substituindo os dados existentes.\n",
    "\n",
    "    Parâmetros:\n",
    "    - dados (DataFrame): DataFrame do pandas contendo os dados a serem carregados.\n",
    "    - caminho_chave (str): Caminho para o arquivo de chave da conta de serviço do Google Cloud.\n",
    "    - projeto_id (str): ID do projeto no Google Cloud.\n",
    "    - dataset_id (str): Nome do dataset no BigQuery onde os dados serão armazenados.\n",
    "    - tabela_id (str): Nome da tabela dentro do dataset onde os dados serão carregados.\n",
    "\n",
    "    Observações:\n",
    "    - A tabela será sobrescrita a cada execução (WRITE_TRUNCATE).\n",
    "    - Apenas as colunas especificadas no schema serão carregadas.\n",
    "    '''\n",
    "    tabela_referencia = f\"{dataset_id}.{tabela_id}\"\n",
    "    cliente = criar_dataset_bigquery(caminho_chave, projeto_id, dataset)    \n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        schema=[\n",
    "            bigquery.SchemaField(\"id\", \"int64\"),\n",
    "            bigquery.SchemaField(\"nivel_1\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"nivel_2\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"nivel_3\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"nivel_4\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"nivel_5\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"nivel_6\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"nivel_7\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"nivel_8\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"shapefile_nome\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"geometria_e_atributos\", \"STRING\"),\n",
    "        ],\n",
    "        write_disposition=\"WRITE_TRUNCATE\", # sobrescreve a tabela (apaga os dados existentes antes de carregar novos)\n",
    "    ) \n",
    "    job = cliente.load_table_from_dataframe(dados, tabela_referencia, job_config=job_config)\n",
    "    job.result()\n",
    "    print(f\"Dados carregados na tabela {tabela_referencia}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd342d3",
   "metadata": {},
   "source": [
    "#### 2 - Lendo os arquivos e criando hierarquia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ec18569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>caminho</th>\n",
       "      <th>nivel_1</th>\n",
       "      <th>nivel_2</th>\n",
       "      <th>nivel_3</th>\n",
       "      <th>nivel_4</th>\n",
       "      <th>nivel_5</th>\n",
       "      <th>nivel_6</th>\n",
       "      <th>nivel_7</th>\n",
       "      <th>nivel_8</th>\n",
       "      <th>shapefile_nome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>shapefiles\\APAs\\APA do Cafuringa\\APA do Cafuri...</td>\n",
       "      <td>APAs</td>\n",
       "      <td>APA do Cafuringa</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>APA do Cafuringa.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>shapefiles\\APAs\\APA do Descoberto\\APA do Desco...</td>\n",
       "      <td>APAs</td>\n",
       "      <td>APA do Descoberto</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>APA do Descoberto.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>shapefiles\\APAs\\APA do Gama Cabeça de Veado\\AP...</td>\n",
       "      <td>APAs</td>\n",
       "      <td>APA do Gama Cabeça de Veado</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>APA do Gama Cabeça de Veado.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>shapefiles\\APAs\\APA do Planalto Central\\APA do...</td>\n",
       "      <td>APAs</td>\n",
       "      <td>APA do Planalto Central</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>APA do Planalto Central.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>shapefiles\\APAs\\APA do São Bartolomeu\\APA do S...</td>\n",
       "      <td>APAs</td>\n",
       "      <td>APA do São Bartolomeu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>APA do São Bartolomeu.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>shapefiles\\APAs\\APA IBRAM 2020\\APA IBRAM 2020.shp</td>\n",
       "      <td>APAs</td>\n",
       "      <td>APA IBRAM 2020</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>APA IBRAM 2020.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>shapefiles\\Limites\\Regiões Administrativas\\Reg...</td>\n",
       "      <td>Limites</td>\n",
       "      <td>Regiões Administrativas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Regiões Administrativas.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>shapefiles\\Limites\\Área Tombada\\Área Tombada.shp</td>\n",
       "      <td>Limites</td>\n",
       "      <td>Área Tombada</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Área Tombada.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>shapefiles\\PDOT\\Conector Ambiental\\Conector Am...</td>\n",
       "      <td>PDOT</td>\n",
       "      <td>Conector Ambiental</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Conector Ambiental.shp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>shapefiles\\PDOT\\Zoneamento\\Zoneamento.shp</td>\n",
       "      <td>PDOT</td>\n",
       "      <td>Zoneamento</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Zoneamento.shp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            caminho  nivel_1  \\\n",
       "0   0  shapefiles\\APAs\\APA do Cafuringa\\APA do Cafuri...     APAs   \n",
       "1   1  shapefiles\\APAs\\APA do Descoberto\\APA do Desco...     APAs   \n",
       "2   2  shapefiles\\APAs\\APA do Gama Cabeça de Veado\\AP...     APAs   \n",
       "3   3  shapefiles\\APAs\\APA do Planalto Central\\APA do...     APAs   \n",
       "4   4  shapefiles\\APAs\\APA do São Bartolomeu\\APA do S...     APAs   \n",
       "5   5  shapefiles\\APAs\\APA IBRAM 2020\\APA IBRAM 2020.shp     APAs   \n",
       "6   6  shapefiles\\Limites\\Regiões Administrativas\\Reg...  Limites   \n",
       "7   7   shapefiles\\Limites\\Área Tombada\\Área Tombada.shp  Limites   \n",
       "8   8  shapefiles\\PDOT\\Conector Ambiental\\Conector Am...     PDOT   \n",
       "9   9          shapefiles\\PDOT\\Zoneamento\\Zoneamento.shp     PDOT   \n",
       "\n",
       "                       nivel_2 nivel_3 nivel_4 nivel_5 nivel_6 nivel_7  \\\n",
       "0             APA do Cafuringa    None    None    None    None    None   \n",
       "1            APA do Descoberto    None    None    None    None    None   \n",
       "2  APA do Gama Cabeça de Veado    None    None    None    None    None   \n",
       "3      APA do Planalto Central    None    None    None    None    None   \n",
       "4        APA do São Bartolomeu    None    None    None    None    None   \n",
       "5               APA IBRAM 2020    None    None    None    None    None   \n",
       "6      Regiões Administrativas    None    None    None    None    None   \n",
       "7                 Área Tombada    None    None    None    None    None   \n",
       "8           Conector Ambiental    None    None    None    None    None   \n",
       "9                   Zoneamento    None    None    None    None    None   \n",
       "\n",
       "  nivel_8                   shapefile_nome  \n",
       "0    None             APA do Cafuringa.shp  \n",
       "1    None            APA do Descoberto.shp  \n",
       "2    None  APA do Gama Cabeça de Veado.shp  \n",
       "3    None      APA do Planalto Central.shp  \n",
       "4    None        APA do São Bartolomeu.shp  \n",
       "5    None               APA IBRAM 2020.shp  \n",
       "6    None      Regiões Administrativas.shp  \n",
       "7    None                 Área Tombada.shp  \n",
       "8    None           Conector Ambiental.shp  \n",
       "9    None                   Zoneamento.shp  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diretorio = \"shapefiles\"\n",
    "df_hierarquia = listar_shapefiles(diretorio)\n",
    "df_hierarquia.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b183e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33 entries, 0 to 32\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              33 non-null     int64 \n",
      " 1   caminho         33 non-null     object\n",
      " 2   nivel_1         33 non-null     object\n",
      " 3   nivel_2         33 non-null     object\n",
      " 4   nivel_3         14 non-null     object\n",
      " 5   nivel_4         2 non-null      object\n",
      " 6   nivel_5         0 non-null      object\n",
      " 7   nivel_6         0 non-null      object\n",
      " 8   nivel_7         0 non-null      object\n",
      " 9   nivel_8         0 non-null      object\n",
      " 10  shapefile_nome  33 non-null     object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_hierarquia.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9a969",
   "metadata": {},
   "source": [
    "#### 3 - Lendos os arquivos _shapefiles_ e criando geodataframe com os dados das geometrias e atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c2696",
   "metadata": {},
   "source": [
    "**Observação:** \n",
    "\n",
    "Considerando que cada arquivo shapefile contém geometrias e atributos distintos, os dados foram consolidados em uma única coluna denominada \"geometria_e_atributos\". Esses dados foram convertidas para o formato JSON em forma de _string_, resultando em dados semiestruturados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "000023c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>caminho</th>\n",
       "      <th>nivel_1</th>\n",
       "      <th>nivel_2</th>\n",
       "      <th>nivel_3</th>\n",
       "      <th>nivel_4</th>\n",
       "      <th>nivel_5</th>\n",
       "      <th>nivel_6</th>\n",
       "      <th>nivel_7</th>\n",
       "      <th>nivel_8</th>\n",
       "      <th>shapefile_nome</th>\n",
       "      <th>geometria_e_atributos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>shapefiles\\APAs\\APA do Cafuringa\\APA do Cafuri...</td>\n",
       "      <td>APAs</td>\n",
       "      <td>APA do Cafuringa</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>APA do Cafuringa.shp</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>shapefiles\\APAs\\APA do Descoberto\\APA do Desco...</td>\n",
       "      <td>APAs</td>\n",
       "      <td>APA do Descoberto</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>APA do Descoberto.shp</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>shapefiles\\APAs\\APA do Gama Cabeça de Veado\\AP...</td>\n",
       "      <td>APAs</td>\n",
       "      <td>APA do Gama Cabeça de Veado</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>APA do Gama Cabeça de Veado.shp</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>shapefiles\\APAs\\APA do Planalto Central\\APA do...</td>\n",
       "      <td>APAs</td>\n",
       "      <td>APA do Planalto Central</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>APA do Planalto Central.shp</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>shapefiles\\APAs\\APA do São Bartolomeu\\APA do S...</td>\n",
       "      <td>APAs</td>\n",
       "      <td>APA do São Bartolomeu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>APA do São Bartolomeu.shp</td>\n",
       "      <td>{\"type\": \"FeatureCollection\", \"features\": [{\"i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            caminho nivel_1  \\\n",
       "0   0  shapefiles\\APAs\\APA do Cafuringa\\APA do Cafuri...    APAs   \n",
       "1   1  shapefiles\\APAs\\APA do Descoberto\\APA do Desco...    APAs   \n",
       "2   2  shapefiles\\APAs\\APA do Gama Cabeça de Veado\\AP...    APAs   \n",
       "3   3  shapefiles\\APAs\\APA do Planalto Central\\APA do...    APAs   \n",
       "4   4  shapefiles\\APAs\\APA do São Bartolomeu\\APA do S...    APAs   \n",
       "\n",
       "                       nivel_2 nivel_3 nivel_4 nivel_5 nivel_6 nivel_7  \\\n",
       "0             APA do Cafuringa    None    None    None    None    None   \n",
       "1            APA do Descoberto    None    None    None    None    None   \n",
       "2  APA do Gama Cabeça de Veado    None    None    None    None    None   \n",
       "3      APA do Planalto Central    None    None    None    None    None   \n",
       "4        APA do São Bartolomeu    None    None    None    None    None   \n",
       "\n",
       "  nivel_8                   shapefile_nome  \\\n",
       "0    None             APA do Cafuringa.shp   \n",
       "1    None            APA do Descoberto.shp   \n",
       "2    None  APA do Gama Cabeça de Veado.shp   \n",
       "3    None      APA do Planalto Central.shp   \n",
       "4    None        APA do São Bartolomeu.shp   \n",
       "\n",
       "                               geometria_e_atributos  \n",
       "0  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "1  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "2  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "3  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  \n",
       "4  {\"type\": \"FeatureCollection\", \"features\": [{\"i...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geoespacial = carregar_geometrias(df_hierarquia)\n",
    "df_geoespacial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af4ce165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33 entries, 0 to 32\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   id                     33 non-null     int64 \n",
      " 1   caminho                33 non-null     object\n",
      " 2   nivel_1                33 non-null     object\n",
      " 3   nivel_2                33 non-null     object\n",
      " 4   nivel_3                14 non-null     object\n",
      " 5   nivel_4                2 non-null      object\n",
      " 6   nivel_5                0 non-null      object\n",
      " 7   nivel_6                0 non-null      object\n",
      " 8   nivel_7                0 non-null      object\n",
      " 9   nivel_8                0 non-null      object\n",
      " 10  shapefile_nome         33 non-null     object\n",
      " 11  geometria_e_atributos  33 non-null     object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_geoespacial.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac03da46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao criar o dataset: [Errno 2] No such file or directory: 'C:/Users/stefanini/Desktop/Demandas/Automacao/projeto III/uso-de-dados-gis-vetoriais-0b65caeff0b0.json'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'load_table_from_dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\STEFAN~1\\AppData\\Local\\Temp/ipykernel_3668/524381620.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"projeto_3\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtabela\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"shapefile\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0menviar_para_bigquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_geoespacial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'caminho'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaminho_chave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprojeto_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtabela\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\STEFAN~1\\AppData\\Local\\Temp/ipykernel_3668/1110016060.py\u001b[0m in \u001b[0;36menviar_para_bigquery\u001b[1;34m(dados, caminho_chave, projeto_id, dataset_id, tabela_id)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mwrite_disposition\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"WRITE_TRUNCATE\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# sobrescreve a tabela (apaga os dados existentes antes de carregar novos)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     ) \n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcliente\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_table_from_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdados\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtabela_referencia\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Dados carregados na tabela {tabela_referencia}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'load_table_from_dataframe'"
     ]
    }
   ],
   "source": [
    "caminho_chave = \"C:\\Users\\stefanini\\projeto III\\credenciais.json\"\n",
    "projeto_id = \"uso-de-dados-gis-vetoriais\"\n",
    "dataset = \"projeto_3\"\n",
    "tabela = \"shapefile\"\n",
    "enviar_para_bigquery(df_geoespacial.drop(columns=['caminho']), caminho_chave, projeto_id, dataset, tabela)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5314e3",
   "metadata": {},
   "source": [
    "### Dados sobre versão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205cc19c",
   "metadata": {},
   "source": [
    "- Python: 3.9.7\n",
    "- pandas==2.2.3\n",
    "- geopandas==1.0.1\n",
    "- fiona==1.10.1\n",
    "- chardet==4.0.0\n",
    "- shapely==2.0.7\n",
    "- google.cloud.bigquery = 3.31.0\n",
    "- google-auth==2.38.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
